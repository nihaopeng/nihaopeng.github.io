<!DOCTYPE html>

<html lang="en"  class="">


<head>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    
    <meta name="keywords" content="">
    
    
    <meta name="description" content="">
    
    <meta name="generator" content="teedoc">
    <meta name="theme" content="teedoc-plugin-theme-default">
    
        
        <meta name="markdown-generator" content="teedoc-plugin-markdown-parser">
        
        <script>
MathJax = {"loader": {"load": ["output/svg"]}, "tex": {"inlineMath": [["$", "$"], ["\\(", "\\)"]]}, "svg": {"fontCache": "global"}};
</script>
        
        <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
        
        <script src="/static/js/theme_default/pre_main.js"></script>
        
        <link rel="stylesheet" href="/static/css/theme_default/prism.min.css" type="text/css"/>
        
        <link rel="stylesheet" href="/static/css/theme_default/viewer.min.css" type="text/css"/>
        
        <link rel="stylesheet" href="/static/css/theme_default/dark.css" type="text/css"/>
        
        <link rel="stylesheet" href="/static/css/theme_default/light.css" type="text/css"/>
        
        <script src="/static/js/theme_default/jquery.min.js"></script>
        
        <script src="/static/js/theme_default/split.js"></script>
        
        <link rel="stylesheet" href="/static/css/search/style.css" type="text/css"/>
        
        <link rel="stylesheet" href="/static/css/custom.css" type="text/css"/>
        
    
    
    <title>FaaSTube: Optimizing GPU-oriented Data Transfer for Serverless Computing - helloyutao</title>
    
    <script type="text/javascript">js_vars = {}</script>
    <script type="text/javascript">metadata = {"tags": [], "date": null, "update": [], "ts": 0, "author": "", "brief": "", "cover": ""}</script>
</head>


<body class="type_doc">
    
    <div id="navbar">
        <div id="navbar_menu">
            <a class="site_title" href="/">
                
                
                    <h2>helloyutao</h2>
                
        </a>
            <a id="navbar_menu_btn"></a>
        </div>
        <div id="navbar_items">
            <div>
                <ul id="nav_left">
<li class="active"><a  href="/docs/">docs</a></li>
</ul>

            </div>
            <div>
                <ul id="nav_right">
</ul>

                <ul class="nav_plugins"><li><a id="themes" class="light"></a></li></ul><ul class="nav_plugins"><li><a id="search"><span class="icon"></span><span class="placeholder">Search</span>
                            <div id="search_hints">
                                <span id="search_input_hint">Keywords separated by space</span>
                                <span id="search_loading_hint">Loading, wait please ...</span>
                                <span id="search_download_err_hint">Download error, please check network and refresh again</span>
                                <span id="search_other_docs_result_hint">Result from other docs</span>
                                <span id="search_curr_doc_result_hint">Result from current doc</span>
                            </div></a></li></ul>
            </div>
        </div>
    </div>
    
    <div id="wrapper">
        <div id="sidebar_wrapper">
            <div id="sidebar">
                <div id="sidebar_title">
                    
                </div>
                <ul class="show">
<li class="not_active no_link"><a><span class="label">algorithms</span><span class="sub_indicator sub_indicator_collapsed"></span></a><ul class="">
<li class="not_active with_link"><a href="/docs/references/algorithms/ann/ann.html"><span class="label">ANN</span><span class=""></span></a></li>
<li class="not_active with_link"><a href="/docs/references/algorithms/moe/index.html"><span class="label">moe</span><span class=""></span></a></li>
<li class="not_active with_link"><a href="/docs/references/algorithms/transformer/index.html"><span class="label">transformer</span><span class=""></span></a></li>
</ul>
</li>
<li class="active_parent no_link"><a><span class="label">ann</span><span class="sub_indicator"></span></a><ul class="show">
<li class="active with_link"><a href="/docs/references/ann/faastube/faastube.html"><span class="label">faastube</span><span class=""></span></a></li>
<li class="not_active with_link"><a href="/docs/references/ann/fusionANNS/fusionANNs.html"><span class="label">fusionANNS</span><span class=""></span></a></li>
<li class="not_active with_link"><a href="/docs/references/ann/second-Tier-memory/second-Tier-memory.html"><span class="label">second-Tier-memory</span><span class=""></span></a></li>
<li class="not_active with_link"><a href="/docs/references/ann/a_realtime_adaptive_multi_stream_GPU_system/adaptive_multi_stream.html"><span class="label">adaptive_multi_stream</span><span class=""></span></a></li>
<li class="not_active with_link"><a href="/docs/references/no_translate.html?ref=ann/runmmy/runmmy.html&from=/docs/references/ann/runmmy/runmmy.html"><span class="label">runmmy</span><span class=""></span></a></li>
</ul>
</li>
<li class="not_active no_link"><a><span class="label">llm</span><span class="sub_indicator sub_indicator_collapsed"></span></a><ul class="">
<li class="not_active with_link"><a href="/docs/references/llm/APC/index.html"><span class="label">APC</span><span class=""></span></a></li>
<li class="not_active with_link"><a href="/docs/references/llm/deepspeed_llm/index.html"><span class="label">deepspeed_llm</span><span class=""></span></a></li>
<li class="not_active with_link"><a href="/docs/references/llm/flashAttention/index.html"><span class="label">flashAttention</span><span class=""></span></a></li>
<li class="not_active with_link"><a href="/docs/references/llm/MLA/index.html"><span class="label">MLA</span><span class=""></span></a></li>
<li class="not_active with_link"><a href="/docs/references/llm/MLAPO/index.html"><span class="label">MLAPO</span><span class=""></span></a></li>
<li class="not_active with_link"><a href="/docs/references/llm/pageAttention/index.html"><span class="label">pageAttention</span><span class=""></span></a></li>
<li class="not_active with_link"><a href="/docs/references/llm/RoPE/index.html"><span class="label">RoPE</span><span class=""></span></a></li>
<li class="not_active with_link"><a href="/docs/references/llm/SLO_PD_multiplex/index.html"><span class="label">SLO_PD_multiplex</span><span class=""></span></a></li>
</ul>
</li>
<li class="not_active no_link"><a><span class="label">moe</span><span class="sub_indicator sub_indicator_collapsed"></span></a><ul class="">
<li class="not_active with_link"><a href="/docs/references/no_translate.html?ref=moe/Learning_Factored_Representations_in_a_Deep_Mixture_of_Experts/index.html&from=/docs/references/moe/Learning_Factored_Representations_in_a_Deep_Mixture_of_Experts/index.html"><span class="label">Learning_Factored_Representations_in_a_Deep_Mixture_of_Experts</span><span class=""></span></a></li>
<li class="not_active with_link"><a href="/docs/references/moe/deepseekMoe/index.html"><span class="label">deepseek Moe</span><span class=""></span></a></li>
<li class="not_active with_link"><a href="/docs/references/moe/parallel_method/index.html"><span class="label">moe_parallel_method</span><span class=""></span></a></li>
</ul>
</li>
<li class="not_active no_link"><a><span class="label">ascend</span><span class="sub_indicator sub_indicator_collapsed"></span></a><ul class="">
<li class="not_active with_link"><a href="/docs/references/ascend/ascend_llm/index.html"><span class="label">ascend_llm</span><span class=""></span></a></li>
</ul>
</li>
<li class="not_active no_link"><a><span class="label">llm</span><span class="sub_indicator sub_indicator_collapsed"></span></a><ul class="">
<li class="not_active with_link"><a href="/docs/references/llm/APC/index.html"><span class="label">APC</span><span class=""></span></a></li>
</ul>
</li>
</ul>

            </div>
        </div>
        <div id="article">
            <div id="menu_wrapper">
                <div id="menu">
                </div>
            </div>
            <div id="content_wrapper">
                <div id="content_body">
                    <div id="article_head">
                        <div id="article_title">
                            
                            <h1>FaaSTube: Optimizing GPU-oriented Data Transfer for Serverless Computing</h1>
                            
                        </div>
                        <div id="article_tags">
                            <ul>
                            
                            </ul>
                        </div>
                        <div id="article_info">
                        <div id="article_info_left">
                            <span class="article_author">
                                
                            </span>
                            
                                <span class="article_date" title="Last modify date: 2025-07-08">
                                    2025-07-08
                                </span>
                            
                        </div>
                        <div id="article_info_right">
                            
                        </div>
                        </div>
                    </div>
                    <div id="article_tools">
                        <span></span>
                        <span id="toc_btn"></span>
                    </div>
                    <div id="update_history">
                        
                    </div>
                    <div id="article_content">
                        
                            <p>推理应用程序通常将多个模型和操作缝合到一个工作流中。这个是本文的前提，因为存在这样的工作流，因此在任务进行的过程中存在大量的数据transfer，这会造成大量的时间开销。</p>
<div style="text-align:center;"><img src="./workflows.png" style="zoom:70%;border-radius: 10px;border:2px solid #23D18B;padding:10px"/></div>
<p>无服务器推理工作流涉及各种类型的数据传递。除了典型的cFunc（cpu函数）到cFunc数据传递之外，还有主机到gFunc（gpu函数）（其中主机表示主机内存中的cFunc或I/O数据）和gFunc到gFunc数据传递。不幸的是，当前的无服务器系统依赖于面向主机的数据传递方法</p>
<div style="text-align:center;"><img src="./QQ20241202-162700.png" style="zoom:70%;border-radius: 10px;border:2px solid #23D18B;padding:10px"/></div>
<p>如上图，对于gpu到gpu的数据传输，首先将数据复制到host，然后再复制到gpu，忽略了nvlink的存在；而对于host到gpu，则采用单个PCIe链路，而忽略了gpu间存在的PCIe链路。如下图，将需要传输的data拆分，分别传输（并行）。</p>
<div style="text-align:center;"><img src="./QQ20241202-163326.png" style="zoom:70%;border-radius: 10px;border:2px solid #23D18B;padding:10px"/></div>
<p>faastube作为数据传输的透明管道，用户不必操心传输的问题，就是开了一个抽象层，用户直接用其抽象层提供的api进行数据传输。</p>
<p>总结存在的第一个问题就是，现有的工作都是单点传输，即传输数据的时候使用一条PCIe总线通路，而没有考虑复杂系统中多条PCIe通路的利用，以及提出相应算法来利用gpu间PCIe的拓扑关系最大化传输效率。</p>
<p>第二个问题是，现在长时间运行的如ML任务，现有的内存管理系统会占用大量的内存，且临时分配内存会带来数据传输延迟，因此提出一个内存池方案，用以缓解内存压力。</p>
<div style="text-align:center;"><img src="./QQ20241202-165639.png" style="zoom:70%;border-radius: 10px;border:2px solid #23D18B;padding:10px"/></div>
<h2 id="%E8%A7%A3%E5%86%B3%E9%97%AE%E9%A2%981">解决问题1</h2>
<p>各种拓扑链接如上图，私以为，除开右上角的链接方式，其余部分不太能够利用到gpu间的传输链路。</p>
<blockquote class="spoiler warning">
<p> 论文中提到，G1-G4可以通过G4-G6-G7加倍带宽（<font color=red>?</font>），这个数据通路不是很符合逻辑（看不懂）。以及后面提到的，G3-G7通过G3-G2-G1-G7以及G3-G4-G6-G7提高带宽，这个可以理解。</p>
</blockquote>
<p>FaaSTube提供统一的数据ID，以简化管理主机端存储（例如，共享主机内存，Redis服务器）和GPU端存储（例如，CUDA IPC句柄）</p>
<p>也就是说该系统将数据进行封装，类似于“页表”机制<font color=red>?</font>为每个页维护一条信息，可以传递这个页的id以获取地址信息。在文中，也就是一个tube，如下图。与页表机制相同，采用多级页表映射机制，这是由于内存空间很大，如果要保证内存划分的细粒度，那就必须要建立多级映射以维护页表。</p>
<div style="text-align:center;"><img src="./QQ20241202-192113.png" style="zoom:70%;border-radius: 10px;border:2px solid #23D18B;padding:10px"/></div>
<p>论文中还提到，数据的复制采用流水线的方式进行，但我并没有看到任何关于流水线的说明。</p>
<p>关于数据传输的带宽控制，论文中提到将全局带宽抽象成整体来分配，如下图，每一个函数的data transfer会被划分为块来进行传输。</p>
<div style="text-align:center;"><img src="./QQ20241202-193111.png" style="zoom:70%;border-radius: 10px;border:2px solid #23D18B;padding:10px"/></div>
<p>PCIe bandwidth schedular中计算$$Rate_{least}=data_{size}/(L_{slo}-L_{infer})$$(最小传输需求)$$L_{infer}$$代表推理计算延迟。SLO代表服务等级目标（serverless的一些专业知识，不是很了解），然后注意到还有一个循环固定缓冲区，类似于双缓冲机制，提前分配两块固定大小的缓冲区，两块缓冲同时使用，一块用来缓存需要传输的数据，另一块用来传输数据，也类似流水线的方式，提高传输效率。</p>
<p>FaaSTube利用并行NVLink路径来增强非统一拓扑中的点对点数据传递。FaaSTube引入了一种竞争感知路径选择算法，可优化NVLink使用，同时最大限度地减少来自其他功能的带宽竞争（避免路径重复）。给定无服务器工作流，FaaSTube首先应用MAPA 中的放置策略将函数分配给GPU，并最大化函数之间的NVLink连接。在确定功能布局后，FaaSTube首先在无服务器工作流中包含的GPU之间分配直接连接路径。如果这些直接NVLinks已经被其他函数占用，FaaSTube将强制其他函数释放路径并重新规划其他路径。</p>
<div style="text-align:center;"><img src="./QQ20241202-194506.png" style="zoom:70%;border-radius: 10px;border:2px solid #23D18B;padding:10px"/></div>
<p>上面那个挺难理解的，直接看他抽象到最上面的算法，1-7行就是搜索空闲路径，然后将空闲path放入paths列表。如果找不到空闲路径，且输入输出带宽没有耗尽，那就搜索忙碌的路径，将占用这条忙碌路径的函数和当前需要路径的函数比较，如果不平衡，且占用当前路径的函数能够切换到另一条路径，那就将该函数挪到另一条路径，当前函数占用该path，这个过程看上去似乎比较复杂，因此作者强调了该过程在实验中仅花费10微秒。</p>
<h2 id="%E8%A7%A3%E5%86%B3%E9%97%AE%E9%A2%982">解决问题2</h2>
<p>1）在每个GPU上提供了一个自动伸缩的内存池，可以根据功能的实际需求弹性伸缩，2）基于请求队列智能地在主机和GPU内存之间迁移数据。</p>
<p>当函数工作负载和中间数据大小动态变化时，这种方法会导致内存占用高达我们实验中实际需求的4倍。虽然PyTorch允许手动回收内存池，但它会回收所有内存块，从而在未来的分配中引入开销。最近的工作，GMlake ，通过使用CUDA虚拟内存和统一的2MB内存块来减少内存池中的碎片，但它仍然缺乏弹性内存回收。此外，GMlake中每个块上昂贵的IPC操作在数据传递中引入了大量开销（在我们的实验中高达45 ms）。</p>
<p>原本keep-alive策略根据每个函数的请求间隔定义函数停留时间，也就是该函数所分配的内存需要维持的时间，但是对于本文所解决的工作流的场景，每个函数的中间数据大小也在波动，因此该波动仍会引起以上提到的问题，因此引入了三个变量用来计算保留的内存大小，如下图：</p>
<div style="text-align:center;">
    <img src="./QQ20241202-200556.png" style="zoom:70%;border-radius: 10px;border:2px solid #23D18B;padding:10px"/>
</div>
<p>f分别是请求间隔（$R_{window}$），中间数据大小($R_{size}$)，以及数据积累度($R_{con}$)，内存保留计算为 $Data_{size}=R_{size} \cdot R_{con}$ ,内存池的最大大小为 $MemPool_{size}=\sum_{func}Data_{size} \cdot 1_{ {R_{window} \bigcap t \neq 0} }$。</p>
<div style="text-align:center;">
    <img src="./QQ20241202-201622.png" style="zoom:70%;border-radius: 10px;border:2px solid #23D18B;padding:10px"/>
</div>
<p>如上图，对于函数a，其请求数据a1由于先入队，所以先出（LRU策略），但是b1需要用到a1，但此时a1已经被复制到主机，b1还需要重新加载数据而带来延迟，因此faastube优先将a2这种不再使用的数据复制到主机（如何知道是否使用<font color=red>?</font>），并且清除不再需要的中间数据，在有足够内存时，将先前迁移出去的数据再迁移回来，以避开transfer的高峰。</p>

                        
                    </div>
                </div>
                <div id="previous_next">
                    <div id="previous">
                        
                        <a href="/docs/references/algorithms/transformer/index.html">
                            <span class="icon"></span>
                            <span class="label">transformer</span>
                        </a>
                        
                    </div>
                    <div id="next">
                        
                        <a href="/docs/references/ann/fusionANNS/fusionANNs.html">
                            <span class="label">fusionANNS</span>
                            <span class="icon"></span>
                        </a>
                        
                    </div>
                </div>
                <div id="comments-container"></div>
            </div>
            <div id="toc_wrapper">
                <div id="toc">
                    <div id="toc_content">
                            
                    </div>
                </div>
            </div>
        </div>
    </div>
    <a id="to_top" href="#"></a>
    <div id="doc_footer">
        <div id="footer">
            <div id="footer_top">
                <ul>
<li><a></a><ul><li><a target="_blank" href="/#"></a></li>
</ul>
</li>
</ul>

            </div>
            <div id="footer_bottom">
                <ul>
<li><a target="_blank" href="https://github.com/teedoc/teedoc">Generated by teedoc</a></li>
</ul>

            </div>
        </div>
    </div>
    
        <script src="/teedoc-plugin-markdown-parser/mermaid.min.js"></script>
    
        <script>mermaid.initialize({startOnLoad:true});</script>
    
        <script src="/static/js/theme_default/tocbot.min.js"></script>
    
        <script src="/static/js/theme_default/main.js"></script>
    
        <script src="/static/js/theme_default/viewer.min.js"></script>
    
        <script src="/static/css/theme_default/prism.min.js"></script>
    
        <script src="/static/js/search/search_main.js"></script>
    
        <script src="/static/js/custom.js"></script>
    
</body>

</html>